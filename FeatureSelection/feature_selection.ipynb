{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "Author: Sandra Godinho Silva \\\n",
    "Most updated version: 0.1 (1/01/2021)\n",
    "\n",
    "## Purpose\n",
    "State the purpose of the notebook.\n",
    "\n",
    "## Methodology\n",
    "Quickly describe assumptions and processing steps.\n",
    "\n",
    "## WIP - improvements\n",
    "Use this section only if the notebook is not final.\n",
    "\n",
    "Notable TODOs:\n",
    "- todo 1;\n",
    "- todo 2;\n",
    "- todo 3.\n",
    "\n",
    "## Results\n",
    "Describe and comment the most important results.\n",
    "\n",
    "## Suggested next steps\n",
    "State suggested next steps, based on results obtained in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import\n",
    "We import all the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T14:44:50.874881Z",
     "start_time": "2019-06-16T14:44:38.616867Z"
    }
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                          1. Importing Libraries                             #\n",
    "###############################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local library import\n",
    "We import all the required local libraries libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T14:44:51.041573Z",
     "start_time": "2019-06-16T14:44:50.878543Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV,   GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter definition\n",
    "We set all relevant parameters for our notebook. By convention, parameters are uppercase, while all the \n",
    "other variables follow Python's guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 1 #int(config.get('Evaluation', 'NumberRuns'))\n",
    "num_test = 3\n",
    "normalization = \"Standard\"\n",
    "\n",
    "train_rf = \"True\"\n",
    "train_logistic_regression = \"False\"\n",
    "train_svm = \"True\"\n",
    "\n",
    "# RF\n",
    "NumberTrees = 500 \n",
    "ValidationModels =  5\n",
    "\n",
    "# SVM\n",
    "GridCV = 5\n",
    "MaxIterations = 1000\n",
    "max_iter = MaxIterations\n",
    "\n",
    "num_cv=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = []\n",
    "\n",
    "if train_rf == \"True\":\n",
    "    to_train.append(\"RF\")\n",
    "if train_logistic_regression == \"True\":\n",
    "    to_train.append(\"Logistic Regression\")\n",
    "if train_svm == \"True\":\n",
    "    to_train.append(\"SVM\")\n",
    "    \n",
    "# Set up DataFrames to store results\n",
    "cv_list = [\"Run_\" + str(x) + \"_CV_\" + str(y) for x in range(num_runs) for y in range(num_test)]\n",
    "auc_df = pd.DataFrame(index=to_train, columns=cv_list)\n",
    "mcc_df = pd.DataFrame(index=to_train, columns=cv_list)\n",
    "precision_df = pd.DataFrame(index=to_train, columns=cv_list)\n",
    "recall_df = pd.DataFrame(index=to_train, columns=cv_list)\n",
    "f1_df = pd.DataFrame(index=to_train, columns=cv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tunning for Random Forest\n",
    "def parameter_tunning_RF():\n",
    "    # number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    \n",
    "    # number of features at every split\n",
    "    max_features = [\"auto\", \"sqrt\"]\n",
    "\n",
    "    # max depth\n",
    "    max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    \n",
    "    # create random grid\n",
    "    random_grid = {\n",
    "     \"n_estimators\": n_estimators,\n",
    "     \"max_features\": max_features,\n",
    "     \"max_depth\": max_depth\n",
    "     }\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    # Random search of parameters\n",
    "    #In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings \n",
    "    #is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
    "    rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    \n",
    "    # Fit the model\n",
    "    rfc_random.fit(X_train, y_train)\n",
    "       \n",
    "    best_parameters = rfc_random.best_params_\n",
    "    print(best_parameters)\n",
    "    \n",
    "    return best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tunning for SVM - Grid Search\n",
    "def parameter_tunning_SVM():\n",
    "\n",
    "    # create random grid\n",
    "    random_grid = {'C': [0.1,1, 10, 100], \n",
    "                  'gamma': [1,0.1,0.01,0.001],\n",
    "                 'kernel'  : ['linear','rbf', 'poly', 'sigmoid']}\n",
    "    \n",
    "    svm = SVC()\n",
    "    # Random search of parameters\n",
    "    #In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings \n",
    "    #is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
    "    svc_random = RandomizedSearchCV(estimator = svm, param_distributions = random_grid, n_iter = 100, cv = 3, \n",
    "                                    verbose=2, random_state=42, n_jobs = -1)\n",
    "    \n",
    "    # Fit the model\n",
    "    svc_random.fit(X_train, y_train)\n",
    "       \n",
    "    best_paramters = svc_random.best_params_\n",
    "    print(best_paramters)\n",
    "    \n",
    "    return best_paramters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "        # create random grid\n",
    "    random_grid = {'C': [0.1,1, 10, 100], \n",
    "                  'gamma': [1,0.1,0.01,0.001],\n",
    "                 'kernel'  : ['linear','rbf', 'poly', 'sigmoid']}\n",
    "    \n",
    "    svm = SVC()\n",
    "    # Random search of parameters\n",
    "    #In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings \n",
    "    #is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
    "    svc_random = RandomizedSearchCV(estimator = svm, param_distributions = random_grid, n_iter = 100, cv = 3, \n",
    "                                    verbose=2, random_state=42, n_jobs = -1)\n",
    "    \n",
    "    # Fit the model\n",
    "    svc_random.fit(X_train, y_train)\n",
    "       \n",
    "    best_paramters = svc_random.best_params_\n",
    "    print(best_paramters)\n",
    "    \n",
    "    return best_paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(y_test, pred, fitted):\n",
    "    stat_dict = {}\n",
    "    stat_dict[\"Accuracy\"] = accuracy_score(y_test, pred)\n",
    "    stat_dict[\"MCC\"] = matthews_corrcoef(y_test, pred)\n",
    "    stat_dict[\"Precision\"] = precision_score(y_test, pred, average='weighted')\n",
    "    stat_dict[\"Recall\"] = recall_score(y_test, pred, average='weighted')\n",
    "    stat_dict[\"F1\"] = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "    #Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores\n",
    "    if num_class == 2:\n",
    "        stat_dict[\"AUC\"] = roc_auc_score(y_test, fitted.predict_proba(X_test)[:,1], average='weighted')\n",
    "    else:\n",
    "        stat_dict[\"AUC\"] = roc_auc_score(y_test, fitted.predict_proba(X_test), average='weighted')   \n",
    "    \n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boxplot(): #to_train, num_class, auc_df, mcc_df, precision_df, recall_df, f1_df, results_path\n",
    "\n",
    "    fig = px.box(pd.melt(auc_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of AUC\",\n",
    "             labels={\"value\": \"AUC\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.box(pd.melt(mcc_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of MMC\",\n",
    "             labels={\"value\": \"MMC\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.box(pd.melt(precision_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of Precision measure\",\n",
    "             labels={\"value\": \"Precision\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.box(pd.melt(recall_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of Recall measure\",\n",
    "             labels={\"value\": \"Recall\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.box(pd.melt(f1_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of F1\",\n",
    "             labels={\"value\": \"F1\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data import\n",
    "We retrieve all the required data for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GT2_Glycos_transf_2</th>\n",
       "      <th>GT9</th>\n",
       "      <th>GT4</th>\n",
       "      <th>GT5</th>\n",
       "      <th>GT25</th>\n",
       "      <th>GH30_1</th>\n",
       "      <th>GH3</th>\n",
       "      <th>GH144</th>\n",
       "      <th>GT51</th>\n",
       "      <th>GH25</th>\n",
       "      <th>CBM50+GH73</th>\n",
       "      <th>CBM32+GH2</th>\n",
       "      <th>GH2</th>\n",
       "      <th>GH109</th>\n",
       "      <th>GT19</th>\n",
       "      <th>GT83</th>\n",
       "      <th>CE11</th>\n",
       "      <th>GH13</th>\n",
       "      <th>GH65</th>\n",
       "      <th>GH97</th>\n",
       "      <th>GH13_19</th>\n",
       "      <th>GT2</th>\n",
       "      <th>CE14</th>\n",
       "      <th>GH92</th>\n",
       "      <th>GT28</th>\n",
       "      <th>...</th>\n",
       "      <th>GH92+GH92</th>\n",
       "      <th>CBM3+GH74</th>\n",
       "      <th>GH5_36</th>\n",
       "      <th>GH102</th>\n",
       "      <th>GH18+CBM6</th>\n",
       "      <th>GH16+GT25</th>\n",
       "      <th>GH123+GH123</th>\n",
       "      <th>CBM35+CBM57+CBM6</th>\n",
       "      <th>CE4+GT2_Glycos_transf_2</th>\n",
       "      <th>GH20+CBM32+CBM5</th>\n",
       "      <th>CE1+CE1</th>\n",
       "      <th>GH39+CBM6</th>\n",
       "      <th>GH81</th>\n",
       "      <th>AA4</th>\n",
       "      <th>CBM32+PL6</th>\n",
       "      <th>CBM77</th>\n",
       "      <th>CBM6+GH3</th>\n",
       "      <th>GH51+CBM35</th>\n",
       "      <th>GH18+CBM73</th>\n",
       "      <th>CBM32+PL7_5</th>\n",
       "      <th>PL7_5+4.2.2.3</th>\n",
       "      <th>CBM47+PL7_3</th>\n",
       "      <th>CBM16+CBM47+PL7_3</th>\n",
       "      <th>CBM47+CBM6+CBM47+CBM6</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non_marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non_marine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 750 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GT2_Glycos_transf_2  GT9  GT4  GT5  GT25  GH30_1  GH3  GH144  GT51  GH25  \\\n",
       "0                    1    1    1    1     0       0    1      0     1     0   \n",
       "1                    1    1    1    1     0       0    1      0     1     0   \n",
       "2                    1    1    1    1     0       0    1      0     1     0   \n",
       "3                    1    1    1    1     0       1    1      1     1     0   \n",
       "4                    1    0    1    1     0       1    1      0     1     0   \n",
       "\n",
       "   CBM50+GH73  CBM32+GH2  GH2  GH109  GT19  GT83  CE11  GH13  GH65  GH97  \\\n",
       "0           1          0    1      1     1     0     1     0     1     1   \n",
       "1           0          0    0      0     1     1     1     0     1     0   \n",
       "2           1          0    0      0     1     1     1     1     1     0   \n",
       "3           0          0    1      0     1     1     1     1     1     1   \n",
       "4           1          0    1      1     1     0     1     1     1     0   \n",
       "\n",
       "   GH13_19  GT2  CE14  GH92  GT28  ...  GH92+GH92  CBM3+GH74  GH5_36  GH102  \\\n",
       "0        0    1     1     1     1  ...          0          0       0      0   \n",
       "1        1    1     1     1     1  ...          0          0       0      0   \n",
       "2        1    1     1     0     1  ...          0          0       0      0   \n",
       "3        1    1     1     0     1  ...          0          0       0      0   \n",
       "4        1    1     1     1     1  ...          0          0       0      0   \n",
       "\n",
       "   GH18+CBM6  GH16+GT25  GH123+GH123  CBM35+CBM57+CBM6  \\\n",
       "0          0          0            0                 0   \n",
       "1          0          0            0                 0   \n",
       "2          0          0            0                 0   \n",
       "3          0          0            0                 0   \n",
       "4          0          0            0                 0   \n",
       "\n",
       "   CE4+GT2_Glycos_transf_2  GH20+CBM32+CBM5  CE1+CE1  GH39+CBM6  GH81  AA4  \\\n",
       "0                        0                0        0          0     0    0   \n",
       "1                        0                0        0          0     0    0   \n",
       "2                        0                0        0          0     0    0   \n",
       "3                        0                0        0          0     0    0   \n",
       "4                        0                0        0          0     0    0   \n",
       "\n",
       "   CBM32+PL6  CBM77  CBM6+GH3  GH51+CBM35  GH18+CBM73  CBM32+PL7_5  \\\n",
       "0          0      0         0           0           0            0   \n",
       "1          0      0         0           0           0            0   \n",
       "2          0      0         0           0           0            0   \n",
       "3          0      0         0           0           0            0   \n",
       "4          0      0         0           0           0            0   \n",
       "\n",
       "   PL7_5+4.2.2.3  CBM47+PL7_3  CBM16+CBM47+PL7_3  CBM47+CBM6+CBM47+CBM6  \\\n",
       "0              0            0                  0                      0   \n",
       "1              0            0                  0                      0   \n",
       "2              0            0                  0                      0   \n",
       "3              0            0                  0                      0   \n",
       "4              0            0                  0                      0   \n",
       "\n",
       "       Origin  \n",
       "0  Non_marine  \n",
       "1      Marine  \n",
       "2      Marine  \n",
       "3      Marine  \n",
       "4  Non_marine  \n",
       "\n",
       "[5 rows x 750 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"cog_genus_counts.csv\", index_col=0)\n",
    "df=pd.read_csv(\"cazymes_PA_metadata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "category= \"Origin\"\n",
    "X = df.copy()\n",
    "y = X.pop(category).values\n",
    "\n",
    "# Stratified k-fold needs np arrays\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GT2_Glycos_transf_2', 'GT9', 'GT4', 'GT5', 'GT25', 'GH30_1', 'GH3',\n",
       "       'GH144', 'GT51', 'GH25',\n",
       "       ...\n",
       "       'CBM32+PL6', 'CBM77', 'CBM6+GH3', 'GH51+CBM35', 'GH18+CBM73',\n",
       "       'CBM32+PL7_5', 'PL7_5+4.2.2.3', 'CBM47+PL7_3', 'CBM16+CBM47+PL7_3',\n",
       "       'CBM47+CBM6+CBM47+CBM6'],\n",
       "      dtype='object', length=749)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=df.drop(columns=category).columns\n",
    "labels_data, label_set = pd.factorize(labels)\n",
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.select_dtypes(include=['int']).columns\n",
    "num_class = len(np.unique(y))\n",
    "\n",
    "rf_scores = pd.DataFrame(index=features)\n",
    "\n",
    "if num_class == 2:\n",
    "    svm_scores = pd.DataFrame(index=features)\n",
    "    logistic_regression_scores = pd.DataFrame(index=features)\n",
    "\n",
    "else:\n",
    "    svm_scores = {}\n",
    "    logistic_regression_scores = {}\n",
    "    for l in label_set:\n",
    "        svm_scores[l] = pd.DataFrame(index=features)     \n",
    "        logistic_regression_scores[l] = pd.DataFrame(index=features) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    # Hypertunning before K folds - SVM\n",
    "    #try: # If it was run before, don't run again\n",
    "   #     best_svm_parameters\n",
    "    #except:\n",
    "     #   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)\n",
    "       \n",
    "        \n",
    "    print(\"RandomSearchCV best parameters for SVM: \" + str(best_svm_parameters))\n",
    "    \n",
    "    \n",
    "                svmc = SVC(kernel=best_svm_parameters[\"kernel\"],\n",
    "                      C = best_svm_parameters[\"C\"],\n",
    "                      gamma = best_svm_parameters[\"gamma\"],\n",
    "                      probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CV\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'max_features': 'auto', 'max_depth': 220}\n",
      "RandomSearchCV best parameters for Random Forest: {'n_estimators': 200, 'max_features': 'auto', 'max_depth': 220}\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandra/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 64 is smaller than n_iter=100. Running 64 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'gamma': 0.1, 'C': 10}\n",
      "RandomSearchCV best parameters for SVM: {'kernel': 'rbf', 'gamma': 0.1, 'C': 10}\n",
      "# RF:\t\t\t0.933654\t0.933654\n",
      "# SVM:\t\t\t0.922450\t0.922450\n",
      "# RF:\t\t\t0.931617\t0.932635\n",
      "# SVM:\t\t\t0.922222\t0.922336\n",
      "# RF:\t\t\t0.889564\t0.918278\n",
      "# SVM:\t\t\t0.894881\t0.913185\n"
     ]
    }
   ],
   "source": [
    "normalization=\"Standard\"\n",
    "num_test=3\n",
    "seeds = np.random.randint(1000, size=num_runs)\n",
    "run = 0\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"Starting CV\")\n",
    "    #Provides train/test indices to split data in train/test sets.\n",
    "    skf = StratifiedKFold(n_splits=num_test, shuffle=True, random_state=seed)\n",
    "    fold = 0\n",
    "    \n",
    "    # Hypertunning before K folds - Random Forest\n",
    "    try: # If it was run before, don't run again\n",
    "        best_rf_parameters\n",
    "    except:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)\n",
    "        best_rf_parameters = parameter_tunning_RF()\n",
    "    print(\"RandomSearchCV best parameters for Random Forest: \" + str(best_rf_parameters))\n",
    "        \n",
    "    # Hypertunning before K folds - Random Forest\n",
    "    try: # If it was run before, don't run again\n",
    "        best_svm_parameters\n",
    "    except:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)\n",
    "        best_svm_parameters = parameter_tunning_SVM()\n",
    "    print(\"RandomSearchCV best parameters for SVM: \" + str(best_svm_parameters))\n",
    "    \n",
    "    # Stratified k-fold\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        # Select and format training and testing sets\n",
    "        X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        cl =  np.unique(y_train)\n",
    "        num_class = len(cl)\n",
    "        \n",
    "        ###################################################################################\n",
    "        # RANDOM FOREST\n",
    "        if train_rf == \"True\":\n",
    "        # Already use best parameters from Hyperparameter tunning\n",
    "            rfc = RandomForestClassifier(n_estimators=best_rf_parameters[\"n_estimators\"], \n",
    "                                         max_features=best_rf_parameters[\"max_features\"], \n",
    "                                         max_depth=best_rf_parameters[\"max_depth\"])\n",
    "\n",
    "            # Fit model\n",
    "            rfc.fit(X_train,y_train)\n",
    "        \n",
    "            # Get predicted labels for the test data:\n",
    "            rfc_predict = rfc.predict(X_test)\n",
    "\n",
    "            # Get ranking of feature importance\n",
    "            feature_importance = rfc.feature_importances_\n",
    "        \n",
    "            stat_dict = get_stats(y_test, rfc_predict, rfc)\n",
    "            \n",
    "            rf_scores[\"Run_\" + str(run) + \"_CV_\" + str(fold)] = feature_importance\n",
    "        \n",
    "            auc_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"AUC\"]\n",
    "            mcc_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"MCC\"]\n",
    "            precision_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"Precision\"]\n",
    "            recall_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"Recall\"]\n",
    "            f1_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"F1\"]\n",
    "\n",
    "            sys.stdout.write(\"\")\n",
    "            print(\"# RF:\\t\\t\\t%f\\t%f\" % (stat_dict[\"AUC\"], auc_df.loc[\"RF\"].mean(axis=0)))    \n",
    "        \n",
    "        ###################################################################################\n",
    "        # SUPPORT VECTOR MACHINES\n",
    "        if train_svm == \"True\":\n",
    "            #num_cv = GridCV\n",
    "            #max_iter = MaxIterations  \n",
    "            \n",
    "            svmc = SVC(kernel=best_svm_parameters[\"kernel\"],\n",
    "                      C = best_svm_parameters[\"C\"],\n",
    "                      gamma = best_svm_parameters[\"gamma\"],\n",
    "                      probability=True)\n",
    "            \n",
    "            # Fit model\n",
    "            svmc.fit(X_train,y_train)\n",
    "            \n",
    "            # Get predicted labels for the test data:\n",
    "            svm_pred = svmc.predict(X_test)\n",
    "            \n",
    "            stat_dict = get_stats(y_test, svm_pred, svmc)\n",
    "            \n",
    "            auc_df.loc[\"SVM\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"AUC\"]\n",
    "            mcc_df.loc[\"SVM\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"MCC\"]\n",
    "            precision_df.loc[\"SVM\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"Precision\"]\n",
    "            recall_df.loc[\"SVM\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"Recall\"]\n",
    "            f1_df.loc[\"SVM\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"F1\"]\n",
    "\n",
    "            sys.stdout.write(\"\")\n",
    "            print(\"# SVM:\\t\\t\\t%f\\t%f\" % (stat_dict[\"AUC\"], auc_df.loc[\"SVM\"].mean(axis=0)))  \n",
    "    \n",
    "        fold +=1\n",
    "    run +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df.to_csv(\"Evaluation_dfs/auc_df.csv\")\n",
    "mcc_df.to_csv(\"Evaluation_dfs/mcc_df.csv\")\n",
    "precision_df.to_csv(\"Evaluation_dfs/precision_df.csv\")\n",
    "recall_df.to_csv(\"Evaluation_dfs/recall_df.csv\")\n",
    "f1_df.to_csv(\"Evaluation_dfs/f1_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - mean & standard deviation values per model: \n",
      "                    RF          SVM\n",
      "AUC        0.92 (0.02)  0.91 (0.02)\n",
      "MCC        0.75 (0.06)  0.69 (0.04)\n",
      "Precision  0.89 (0.03)  0.86 (0.02)\n",
      "Recall     0.88 (0.03)  0.85 (0.02)\n",
      "F1         0.88 (0.03)  0.85 (0.02)\n",
      "\n",
      "Best model: RF\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#                          X. Choosing best model                             #\n",
    "###############################################################################\n",
    "\n",
    "results_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=to_train)\n",
    "results_df_nr = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=to_train)\n",
    "\n",
    "for model in to_train:\n",
    "    results_df.loc[\"AUC\"][model] = \"{:.2f}\".format(auc_df.loc[model].mean())+ \" (\" + \"{:.2f}\".format(auc_df.loc[model].std()) + \")\"     \n",
    "    results_df_nr.loc[\"AUC\"][model] = auc_df.loc[model].mean()   \n",
    "    \n",
    "    results_df.loc[\"MCC\"][model] = \"{:.2f}\".format(mcc_df.loc[model].mean()) + \" (\" + \"{:.2f}\".format(mcc_df.loc[model].std()) + \")\"\n",
    "    results_df_nr.loc[\"MCC\"][model] = mcc_df.loc[model].mean()   \n",
    "    \n",
    "    results_df.loc[\"Precision\"][model] = \"{:.2f}\".format(precision_df.loc[model].mean()) + \" (\" + \"{:.2f}\".format(precision_df.loc[model].std()) + \")\"\n",
    "    results_df_nr.loc[\"Precision\"][model] = precision_df.loc[model].mean()   \n",
    "\n",
    "    results_df.loc[\"Recall\"][model] = \"{:.2f}\".format(recall_df.loc[model].mean()) + \" (\" + \"{:.2f}\".format(recall_df.loc[model].std()) + \")\"\n",
    "    results_df_nr.loc[\"Recall\"][model] = recall_df.loc[model].mean()   \n",
    "\n",
    "    results_df.loc[\"F1\"][model] = \"{:.2f}\".format(f1_df.loc[model].mean()) + \" (\" + \"{:.2f}\".format(f1_df.loc[model].std()) + \")\"\n",
    "    results_df_nr.loc[\"F1\"][model] = f1_df.loc[model].mean()   \n",
    "\n",
    "# Find model with best metrics    \n",
    "results_df_nr.loc[\"Total\",:] = results_df_nr.sum(axis=0).divide(5).round(2)\n",
    "\n",
    "best={}\n",
    "for model in to_train:\n",
    "    best[model] = results_df_nr.loc[\"Total\",:][model]\n",
    "    \n",
    "best_model = max(best, key=best.get)\n",
    "\n",
    "print(\"Results - mean & standard deviation values per model: \")\n",
    "print(results_df.head(20))\n",
    "print(\"\")\n",
    "print(\"Best model: \" + str(best_model))\n",
    "\n",
    "results_df.to_csv(\"Evaluation_dfs/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "\n",
    "rf_ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "svm_ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "\n",
    "model_rankings = {}\n",
    "\n",
    "if \"RF\" in to_train:\n",
    "    for col in rf_scores.columns:\n",
    "        rank_list = rf_scores[col].rank(ascending=False).sort_values(ascending=True).index.values\n",
    "        ranking_df[\"RF_\" + col] = rank_list\n",
    "        rf_ranking_df[\"RF_\" + col] = rank_list\n",
    "\n",
    "        model_rankings[\"RF\"] = rf_scores.median(axis=1).sort_values(ascending=False).index.values\n",
    "            \n",
    "if \"SVM\" in to_train and num_class == 2:\n",
    "    for col in svm_scores.columns:\n",
    "        rank_list = svm_scores[col].abs().rank(ascending=False).sort_values(ascending=True).index.values\n",
    "        ranking_df[\"SVM_\" + col] = rank_list\n",
    "        svm_ranking_df[\"SVM_\" + col] = rank_list\n",
    "        \n",
    "        model_rankings[\"SVM\"] = svm_scores.median(axis=1).sort_values(ascending=False).index.values\n",
    "        \n",
    "elif \"SVM\" in to_train and num_class > 2:\n",
    "    svm_joint_scores = pd.DataFrame(index=features, columns=svm_ranking_df.columns)\n",
    "    for col in svm_scores[label_set[0]].columns:\n",
    "        for l in range(len(label_set)):\n",
    "            if l == 0:\n",
    "                score_list = svm_scores[label_set[l]][[col]]\n",
    "            else:\n",
    "                score_list = score_list.join(svm_scores[label_set[l]][[col]], rsuffix=l)\n",
    "        ranking_df[\"SVM_\" + col] = score_list.abs().mean(axis=1).rank(ascending=False).sort_values(ascending=True).index.values\n",
    "        svm_ranking_df[\"SVM_\" + col] = score_list.abs().mean(axis=1).rank(ascending=False).sort_values(ascending=True).index.values\n",
    "        svm_joint_scores[\"SVM_\" + col] = score_list.abs().mean(axis=1)\n",
    "            \n",
    "    for l in range(len(label_set)):\n",
    "        if l == 0:\n",
    "            score_list = svm_scores[label_set[l]].abs()\n",
    "        else:\n",
    "            score_list = score_list.join(svm_scores[label_set[l]].abs(), rsuffix=l)            \n",
    "    model_rankings[\"SVM\"] = score_list.abs().mean(axis=1).sort_values(ascending=False).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SVM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4e501dcc5f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0msvm_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation_dfs/svm_feature_scores_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation_dfs/svm_rank_list.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_rankings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SVM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'SVM'"
     ]
    }
   ],
   "source": [
    "if \"RF\" in to_train:\n",
    "    rf_ranking_df.to_csv(\"Evaluation_dfs/rf_feature_ranks.csv\")\n",
    "    rf_scores.to_csv(\"Evaluation_dfs/rf_feature_scores.csv\")\n",
    "    np.savetxt(\"Evaluation_dfs/rf_rank_list.txt\", model_rankings[\"RF\"], fmt=\"%s\")\n",
    "    \n",
    "if \"SVM\" in to_train:\n",
    "    svm_ranking_df.to_csv(\"Evaluation_dfs/svm_feature_ranks.csv\")\n",
    "    if num_class==2:\n",
    "        svm_scores.to_csv(\"Evaluation_dfs/svm_feature_scores.csv\")\n",
    "    else:\n",
    "        for l in label_set:\n",
    "            svm_scores[l].to_csv(\"Evaluation_dfs/svm_feature_scores_\" + str(l) + \".csv\")\n",
    "    np.savetxt(\"Evaluation_dfs/svm_rank_list.txt\", model_rankings[\"SVM\"], fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sfm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4e770e33be12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Train the selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sfm' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature Selection implementation\n",
    "if best_model == \"RF\":\n",
    "    rfc = RandomForestClassifier(n_estimators=best_rf_parameters[\"n_estimators\"], \n",
    "                                         max_features=best_rf_parameters[\"max_features\"], \n",
    "                                         max_depth=best_rf_parameters[\"max_depth\"])\n",
    "    # Fit model\n",
    "    rfc.fit(X_train,y_train)\n",
    "    \n",
    "\n",
    "\n",
    "    # Train the selector\n",
    "    sfm.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Get predicted labels for the test data:\n",
    "    rfc_predict = rfc.predict(X_test)\n",
    "\n",
    "    # Cross-validation\n",
    "    scores = cross_val_score(rfc, X, y, cv=5)\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "    \n",
    "    # Get ranking of feature importance\n",
    "    feature_importance = rfc.feature_importances_\n",
    "        \n",
    "    stat_dict_final = get_stats(y_test, rfc_predict, rfc)\n",
    "            \n",
    "elif best_model == \"SVM\":\n",
    "    \n",
    "    clf = SVC(kernel=best_svm_parameters[\"kernel\"],\n",
    "                      C = best_svm_parameters[\"C\"],\n",
    "                      gamma = best_svm_parameters[\"gamma\"],\n",
    "                      probability=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "    svm_pred = clf.predict(X_test)\n",
    "        \n",
    "rf_scores[\"Run_\" + str(run) + \"_CV_\" + str(fold)] = feature_importance\n",
    "        \n",
    "auc_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"AUC\"]\n",
    "mcc_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"MCC\"]\n",
    "precision_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"Precision\"]\n",
    "recall_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"Recall\"]\n",
    "f1_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"F1\"]\n",
    "\n",
    "sys.stdout.write(\"\")\n",
    "print(str(best_model) + \" AUC: \" + str(stat_dict_final[\"AUC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "rf = RandomForestClassifier(n_estimators = 100, class_weight='balanced', random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"lightsalmon\", align=\"center\")\n",
    "#plt.xticks(range(X_train.shape[1]), X_train.feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category= \"Origin\"\n",
    "X = df.copy()\n",
    "y = X.pop(category).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200, class_weight='balanced', max_depth=4, n_jobs=-1)\n",
    "clf.fit(X_train[green_area].to_numpy(), y_train)\n",
    "preds = clf.predict(X_test[green_area].to_numpy())\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "\n",
    "if best_model == \"RF\":\n",
    "    rfecv = RFECV(estimator=rfc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "    rfecv.fit(X, y)\n",
    "    \n",
    "elif best_model == \"SVM\"\n",
    "    \n",
    "    rfecv = RFECV(estimator=svmc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "    rfecv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected features labels\n",
    "feature_names = df.columns\n",
    "selected_features = feature_names[feature_selector.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# Feature Selection implementation\n",
    "if best_model == \"RF\":\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "sfm = SelectFromModel(clf, threshold=0.15)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "\n",
    "rf_ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "svm_ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "\n",
    "model_rankings = {}\n",
    "        \n",
    "if \"RF\" in to_train:\n",
    "    for col in rf_scores.columns:\n",
    "        rank_list = rf_scores[col].rank(ascending=False).sort_values(ascending=True).index.values\n",
    "        ranking_df[\"RF_\" + col] = rank_list\n",
    "        rf_ranking_df[\"RF_\" + col] = rank_list\n",
    "    model_rankings[\"RF\"] = rf_scores.median(axis=1).sort_values(ascending=False).index.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    if \"RF\" in to_train:\n",
    "        rf_median_scores = rf_scores.median(axis=1)        \n",
    "        fig = plt.figure(dpi=300, figsize=(9,9), tight_layout=True)\n",
    "        \n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.title(\"RF Feature Scores\")\n",
    "        sns.distplot(list(rf_median_scores))\n",
    "        plt.savefig(\"RF_scores.png\")\n",
    "        #plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def generate_score_distributions():\n",
    "\n",
    "    if \"RF\" in to_train:\n",
    "        rf_median_scores = rf_scores.median(axis=1)        \n",
    "        fig = plt.figure(dpi=300, figsize=(9,9), tight_layout=True)\n",
    "        \n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.title(\"RF Feature Scores\")\n",
    "        sns.distplot(list(rf_median_scores))\n",
    "        plt.savefig(\"RF_scores.png\")\n",
    "        #plt.clf()\n",
    "\n",
    "    if \"SVM\" in to_train:\n",
    "        fig = plt.figure(dpi=300, figsize=(9,9), tight_layout=True)\n",
    "\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.title(\"SVM Feature Scores\")\n",
    "        if num_class == 2:\n",
    "            svm_median_scores = svm_scores.median(axis=1).values\n",
    "            sns.distplot(svm_median_scores)\n",
    "        else:\n",
    "            for l in label_set:\n",
    "                svm_median_scores = svm_scores[l].median(axis=1).values  \n",
    "                sns.distplot(svm_median_scores, label=str(l).title())\n",
    "            plt.legend()\n",
    "        plt.savefig(\"SVM_scores.png\")\n",
    "        #plt.clf()\n",
    "\n",
    "    return\n",
    "\n",
    "generate_score_distributions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
