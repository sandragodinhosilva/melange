{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "Author: Sandra Godinho Silva \\\n",
    "Most updated version: 0.1 (1/01/2021)\n",
    "\n",
    "## Purpose\n",
    "State the purpose of the notebook.\n",
    "\n",
    "## Methodology\n",
    "Quickly describe assumptions and processing steps.\n",
    "\n",
    "## WIP - improvements\n",
    "Use this section only if the notebook is not final.\n",
    "\n",
    "Notable TODOs:\n",
    "- todo 1;\n",
    "- todo 2;\n",
    "- todo 3.\n",
    "\n",
    "## Results\n",
    "Describe and comment the most important results.\n",
    "\n",
    "## Suggested next steps\n",
    "State suggested next steps, based on results obtained in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import\n",
    "We import all the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T14:44:50.874881Z",
     "start_time": "2019-06-16T14:44:38.616867Z"
    }
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                          1. Importing Libraries                             #\n",
    "###############################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local library import\n",
    "We import all the required local libraries libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T14:44:51.041573Z",
     "start_time": "2019-06-16T14:44:50.878543Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV,   GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter definition\n",
    "We set all relevant parameters for our notebook. By convention, parameters are uppercase, while all the \n",
    "other variables follow Python's guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 1 #int(config.get('Evaluation', 'NumberRuns'))\n",
    "num_test = 3\n",
    "normalization = \"Standard\"\n",
    "\n",
    "train_rf = \"True\"\n",
    "train_logistic_regression = \"False\"\n",
    "train_svm = \"False\"\n",
    "\n",
    "# RF\n",
    "NumberTrees = 500 \n",
    "ValidationModels =  5\n",
    "\n",
    "# SVM\n",
    "GridCV = 5\n",
    "MaxIterations = 1000\n",
    "max_iter = MaxIterations\n",
    "\n",
    "num_cv=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = []\n",
    "\n",
    "if train_rf == \"True\":\n",
    "    to_train.append(\"RF\")\n",
    "if train_logistic_regression == \"True\":\n",
    "    to_train.append(\"Logistic Regression\")\n",
    "if train_svm == \"True\":\n",
    "    to_train.append(\"SVM\")\n",
    "    \n",
    "# Set up DataFrames to store results\n",
    "cv_list = [\"Run_\" + str(x) + \"_CV_\" + str(y) for x in range(num_runs) for y in range(num_test)]\n",
    "auc_df = pd.DataFrame(index=to_train, columns=cv_list)\n",
    "mcc_df = pd.DataFrame(index=to_train, columns=cv_list)\n",
    "precision_df = pd.DataFrame(index=to_train, columns=cv_list)\n",
    "recall_df = pd.DataFrame(index=to_train, columns=cv_list)\n",
    "f1_df = pd.DataFrame(index=to_train, columns=cv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tunning for Random Forest\n",
    "def parameter_tunning_RF():\n",
    "    # number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    \n",
    "    # number of features at every split\n",
    "    max_features = [\"auto\", \"sqrt\"]\n",
    "\n",
    "    # max depth\n",
    "    max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    \n",
    "    # create random grid\n",
    "    random_grid = {\n",
    "     \"n_estimators\": n_estimators,\n",
    "     \"max_features\": max_features,\n",
    "     \"max_depth\": max_depth\n",
    "     }\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    # Random search of parameters\n",
    "    #In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings \n",
    "    #is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
    "    rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    \n",
    "    # Fit the model\n",
    "    rfc_random.fit(X_train, y_train)\n",
    "       \n",
    "    best_parameters = rfc_random.best_params_\n",
    "    print(best_parameters)\n",
    "    \n",
    "    return best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(y_test, pred, fitted):\n",
    "    stat_dict = {}\n",
    "    stat_dict[\"Accuracy\"] = accuracy_score(y_test, pred)\n",
    "    stat_dict[\"MCC\"] = matthews_corrcoef(y_test, pred)\n",
    "    stat_dict[\"Precision\"] = precision_score(y_test, pred, average='weighted')\n",
    "    stat_dict[\"Recall\"] = recall_score(y_test, pred, average='weighted')\n",
    "    stat_dict[\"F1\"] = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "    #Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores\n",
    "    if num_class == 2:\n",
    "        stat_dict[\"AUC\"] = roc_auc_score(y_test, fitted.predict_proba(X_test)[:,1], average='weighted')\n",
    "    else:\n",
    "        stat_dict[\"AUC\"] = roc_auc_score(y_test, fitted.predict_proba(X_test), average='weighted')   \n",
    "    \n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boxplot(): #to_train, num_class, auc_df, mcc_df, precision_df, recall_df, f1_df, results_path\n",
    "\n",
    "    fig = px.box(pd.melt(auc_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of AUC\",\n",
    "             labels={\"value\": \"AUC\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.box(pd.melt(mcc_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of MMC\",\n",
    "             labels={\"value\": \"MMC\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.box(pd.melt(precision_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of Precision measure\",\n",
    "             labels={\"value\": \"Precision\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.box(pd.melt(recall_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of Recall measure\",\n",
    "             labels={\"value\": \"Recall\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.box(pd.melt(f1_df.transpose()), x=\"variable\", y=\"value\", \n",
    "             color=\"variable\",\n",
    "             title=\"Box plot of F1\",\n",
    "             labels={\"value\": \"F1\",\n",
    "                     \"variable\": \"Model\"})\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data import\n",
    "We retrieve all the required data for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GT2_Glycos_transf_2</th>\n",
       "      <th>GT9</th>\n",
       "      <th>GT4</th>\n",
       "      <th>GT5</th>\n",
       "      <th>GT25</th>\n",
       "      <th>GH30_1</th>\n",
       "      <th>GH3</th>\n",
       "      <th>GH144</th>\n",
       "      <th>GT51</th>\n",
       "      <th>GH25</th>\n",
       "      <th>CBM50+GH73</th>\n",
       "      <th>CBM32+GH2</th>\n",
       "      <th>GH2</th>\n",
       "      <th>GH109</th>\n",
       "      <th>GT19</th>\n",
       "      <th>GT83</th>\n",
       "      <th>CE11</th>\n",
       "      <th>GH13</th>\n",
       "      <th>GH65</th>\n",
       "      <th>GH97</th>\n",
       "      <th>GH13_19</th>\n",
       "      <th>GT2</th>\n",
       "      <th>CE14</th>\n",
       "      <th>GH92</th>\n",
       "      <th>GT28</th>\n",
       "      <th>...</th>\n",
       "      <th>GH92+GH92</th>\n",
       "      <th>CBM3+GH74</th>\n",
       "      <th>GH5_36</th>\n",
       "      <th>GH102</th>\n",
       "      <th>GH18+CBM6</th>\n",
       "      <th>GH16+GT25</th>\n",
       "      <th>GH123+GH123</th>\n",
       "      <th>CBM35+CBM57+CBM6</th>\n",
       "      <th>CE4+GT2_Glycos_transf_2</th>\n",
       "      <th>GH20+CBM32+CBM5</th>\n",
       "      <th>CE1+CE1</th>\n",
       "      <th>GH39+CBM6</th>\n",
       "      <th>GH81</th>\n",
       "      <th>AA4</th>\n",
       "      <th>CBM32+PL6</th>\n",
       "      <th>CBM77</th>\n",
       "      <th>CBM6+GH3</th>\n",
       "      <th>GH51+CBM35</th>\n",
       "      <th>GH18+CBM73</th>\n",
       "      <th>CBM32+PL7_5</th>\n",
       "      <th>PL7_5+4.2.2.3</th>\n",
       "      <th>CBM47+PL7_3</th>\n",
       "      <th>CBM16+CBM47+PL7_3</th>\n",
       "      <th>CBM47+CBM6+CBM47+CBM6</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non_marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non_marine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 750 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GT2_Glycos_transf_2  GT9  GT4  GT5  GT25  GH30_1  GH3  GH144  GT51  GH25  \\\n",
       "0                    1    1    1    1     0       0    1      0     1     0   \n",
       "1                    1    1    1    1     0       0    1      0     1     0   \n",
       "2                    1    1    1    1     0       0    1      0     1     0   \n",
       "3                    1    1    1    1     0       1    1      1     1     0   \n",
       "4                    1    0    1    1     0       1    1      0     1     0   \n",
       "\n",
       "   CBM50+GH73  CBM32+GH2  GH2  GH109  GT19  GT83  CE11  GH13  GH65  GH97  \\\n",
       "0           1          0    1      1     1     0     1     0     1     1   \n",
       "1           0          0    0      0     1     1     1     0     1     0   \n",
       "2           1          0    0      0     1     1     1     1     1     0   \n",
       "3           0          0    1      0     1     1     1     1     1     1   \n",
       "4           1          0    1      1     1     0     1     1     1     0   \n",
       "\n",
       "   GH13_19  GT2  CE14  GH92  GT28  ...  GH92+GH92  CBM3+GH74  GH5_36  GH102  \\\n",
       "0        0    1     1     1     1  ...          0          0       0      0   \n",
       "1        1    1     1     1     1  ...          0          0       0      0   \n",
       "2        1    1     1     0     1  ...          0          0       0      0   \n",
       "3        1    1     1     0     1  ...          0          0       0      0   \n",
       "4        1    1     1     1     1  ...          0          0       0      0   \n",
       "\n",
       "   GH18+CBM6  GH16+GT25  GH123+GH123  CBM35+CBM57+CBM6  \\\n",
       "0          0          0            0                 0   \n",
       "1          0          0            0                 0   \n",
       "2          0          0            0                 0   \n",
       "3          0          0            0                 0   \n",
       "4          0          0            0                 0   \n",
       "\n",
       "   CE4+GT2_Glycos_transf_2  GH20+CBM32+CBM5  CE1+CE1  GH39+CBM6  GH81  AA4  \\\n",
       "0                        0                0        0          0     0    0   \n",
       "1                        0                0        0          0     0    0   \n",
       "2                        0                0        0          0     0    0   \n",
       "3                        0                0        0          0     0    0   \n",
       "4                        0                0        0          0     0    0   \n",
       "\n",
       "   CBM32+PL6  CBM77  CBM6+GH3  GH51+CBM35  GH18+CBM73  CBM32+PL7_5  \\\n",
       "0          0      0         0           0           0            0   \n",
       "1          0      0         0           0           0            0   \n",
       "2          0      0         0           0           0            0   \n",
       "3          0      0         0           0           0            0   \n",
       "4          0      0         0           0           0            0   \n",
       "\n",
       "   PL7_5+4.2.2.3  CBM47+PL7_3  CBM16+CBM47+PL7_3  CBM47+CBM6+CBM47+CBM6  \\\n",
       "0              0            0                  0                      0   \n",
       "1              0            0                  0                      0   \n",
       "2              0            0                  0                      0   \n",
       "3              0            0                  0                      0   \n",
       "4              0            0                  0                      0   \n",
       "\n",
       "       Origin  \n",
       "0  Non_marine  \n",
       "1      Marine  \n",
       "2      Marine  \n",
       "3      Marine  \n",
       "4  Non_marine  \n",
       "\n",
       "[5 rows x 750 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"cog_genus_counts.csv\", index_col=0)\n",
    "df=pd.read_csv(\"cazymes_PA_metadata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "category= \"Origin\"\n",
    "X = df.copy()\n",
    "y = X.pop(category).values\n",
    "\n",
    "# Stratified k-fold needs np arrays\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GT2_Glycos_transf_2', 'GT9', 'GT4', 'GT5', 'GT25', 'GH30_1', 'GH3',\n",
       "       'GH144', 'GT51', 'GH25',\n",
       "       ...\n",
       "       'CBM32+PL6', 'CBM77', 'CBM6+GH3', 'GH51+CBM35', 'GH18+CBM73',\n",
       "       'CBM32+PL7_5', 'PL7_5+4.2.2.3', 'CBM47+PL7_3', 'CBM16+CBM47+PL7_3',\n",
       "       'CBM47+CBM6+CBM47+CBM6'],\n",
       "      dtype='object', length=749)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=df.drop(columns=category).columns\n",
    "labels_data, label_set = pd.factorize(labels)\n",
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.select_dtypes(include=['int']).columns\n",
    "num_class = len(np.unique(y))\n",
    "\n",
    "rf_scores = pd.DataFrame(index=features)\n",
    "\n",
    "if num_class == 2:\n",
    "    svm_scores = pd.DataFrame(index=features)\n",
    "    logistic_regression_scores = pd.DataFrame(index=features)\n",
    "\n",
    "else:\n",
    "    svm_scores = {}\n",
    "    logistic_regression_scores = {}\n",
    "    for l in label_set:\n",
    "        svm_scores[l] = pd.DataFrame(index=features)     \n",
    "        logistic_regression_scores[l] = pd.DataFrame(index=features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Filter Method: Correlation-Based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1004, 749)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'corr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-149644f2e3f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Filter Method: Spearman's Cross Correlation > 0.95\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Make correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcorr_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"spearman\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Draw the heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'corr'"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#                        3. Create train and test set                         #\n",
    "###############################################################################\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,\n",
    "                                                    random_state = 1000)\n",
    "print(X_train.shape)\n",
    "###############################################################################\n",
    "#              6. Feature Selection: Removing highly correlated features      #\n",
    "###############################################################################\n",
    "# Filter Method: Spearman's Cross Correlation > 0.95\n",
    "# Make correlation matrix\n",
    "corr_matrix = X_train.corr(method = \"spearman\").abs()\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.set(font_scale = 1.0)\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "sns.heatmap(corr_matrix, cmap= \"YlGnBu\", square=True, ax = ax)\n",
    "f.tight_layout()\n",
    "plt.savefig(\"correlation_matrix.png\", dpi = 1080)\n",
    "\n",
    "# Select upper triangle of matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# Drop features\n",
    "X_train = X_train.drop(to_drop, axis = 1)\n",
    "X_test = X_test.drop(to_drop, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CV\n",
      "RandomSearchCV best parameters for Random Forest: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 300}\n",
      "[   0    1    2    4    6    7    9   10   11   13   14   16   21   22\n",
      "   23   24   28   30   31   33   34   35   36   37   38   42   44   47\n",
      "   48   49   50   51   53   55   59   60   63   64   66   67   71   72\n",
      "   73   75   78   79   80   81   82   83   84   86   90   92   94   95\n",
      "   96   98   99  101  102  103  104  105  106  107  108  111  114  115\n",
      "  116  118  119  120  122  123  124  125  129  130  131  132  134  135\n",
      "  136  138  139  141  142  143  144  145  147  148  149  150  151  152\n",
      "  153  154  155  156  158  167  168  169  171  172  174  175  176  177\n",
      "  178  179  181  182  183  184  186  187  189  191  193  194  195  196\n",
      "  197  198  200  201  203  206  207  209  210  211  212  213  214  215\n",
      "  216  220  221  222  223  224  226  228  229  231  232  233  234  238\n",
      "  239  240  242  244  245  246  248  249  250  251  252  253  254  257\n",
      "  259  260  261  263  265  266  268  270  271  273  276  278  280  281\n",
      "  282  283  287  290  291  295  297  298  299  300  302  303  304  305\n",
      "  306  309  311  312  314  315  316  317  318  319  320  322  328  329\n",
      "  330  331  332  336  337  338  339  341  343  344  345  346  348  349\n",
      "  350  352  353  355  356  357  358  359  361  364  367  368  369  370\n",
      "  371  372  374  376  377  378  380  382  383  384  386  387  389  390\n",
      "  391  392  393  394  395  396  397  398  400  401  402  403  404  406\n",
      "  408  409  410  413  414  415  417  418  420  421  422  426  427  429\n",
      "  430  431  432  433  436  438  439  442  443  444  445  446  447  448\n",
      "  449  450  451  453  454  456  457  459  460  461  462  464  466  467\n",
      "  468  469  470  471  472  473  474  476  477  478  480  481  482  483\n",
      "  484  485  486  487  488  489  491  492  493  494  495  498  499  501\n",
      "  503  506  507  508  510  511  512  513  514  515  517  518  519  520\n",
      "  521  525  526  527  528  532  533  534  536  538  540  543  545  546\n",
      "  547  549  550  551  553  554  556  557  559  561  562  564  565  568\n",
      "  569  570  571  572  578  580  582  583  584  585  586  587  588  590\n",
      "  593  594  595  596  598  599  602  603  604  606  607  609  610  611\n",
      "  612  613  614  615  617  619  620  622  624  625  626  627  628  629\n",
      "  632  634  635  636  637  638  639  640  641  642  643  645  646  647\n",
      "  648  649  650  651  652  653  654  657  659  660  662  663  665  666\n",
      "  667  668  669  670  671  672  673  675  676  677  678  679  681  682\n",
      "  683  684  685  686  687  688  689  690  691  692  693  695  696  698\n",
      "  701  702  703  705  706  710  711  713  715  716  717  722  724  725\n",
      "  726  729  730  731  732  733  734  735  736  737  739  740  741  742\n",
      "  743  744  745  747  748  750  751  752  753  754  755  758  759  760\n",
      "  762  764  765  768  769  770  772  774  776  778  779  780  781  782\n",
      "  783  784  785  788  789  790  791  793  796  797  798  799  801  802\n",
      "  804  805  807  810  811  812  813  816  818  819  820  822  823  824\n",
      "  826  827  829  830  831  832  833  834  836  838  839  840  844  845\n",
      "  846  847  849  851  852  854  856  859  864  865  867  868  871  872\n",
      "  873  876  877  878  879  880  883  884  885  887  888  889  891  894\n",
      "  895  896  897  901  902  903  908  910  911  913  914  915  918  920\n",
      "  921  922  923  924  925  928  929  931  933  934  935  936  938  946\n",
      "  947  948  951  952  953  954  955  957  958  959  961  963  964  966\n",
      "  967  968  969  970  973  974  977  978  979  980  981  982  984  986\n",
      "  987  988  989  993  997  998  999 1000 1003 1004 1006 1007 1008 1009\n",
      " 1010 1011 1015 1017 1018 1019 1020 1021 1022 1024 1025 1026 1027 1028\n",
      " 1029 1031 1032 1033 1034 1035 1038 1039 1040 1044 1045 1046 1047 1048\n",
      " 1049 1050 1051 1052 1053 1054 1057 1059 1061 1062 1063 1065 1067 1068\n",
      " 1069 1071 1072 1073 1074 1075 1077 1078 1079 1080 1081 1083 1084 1085\n",
      " 1086 1087 1088 1089 1090 1091 1092 1095 1097 1098 1099 1100 1101 1102\n",
      " 1104 1105 1106 1110 1114 1115 1118 1119 1120 1122 1123 1127 1128 1129\n",
      " 1131 1132 1133 1138 1139 1140 1141 1142 1143 1145 1146 1147 1148 1149\n",
      " 1153 1154 1157 1158 1159 1163 1165 1167 1168 1169 1170 1171 1172 1173\n",
      " 1174 1175 1176 1177 1178 1179 1180 1182 1184 1185 1187 1190 1191 1192\n",
      " 1193 1196 1197 1198 1199 1200 1201 1203 1204 1205 1206 1212 1215 1216\n",
      " 1217 1218 1219 1221 1222 1223 1228 1229 1232 1233 1234 1237 1238 1239\n",
      " 1240 1241 1242 1243 1244 1245 1246 1248 1250 1254 1255]\n",
      "[   3    5    8   12   15   17   18   19   20   25   26   27   29   32\n",
      "   39   40   41   43   45   46   52   54   56   57   58   61   62   65\n",
      "   68   69   70   74   76   77   85   87   88   89   91   93   97  100\n",
      "  109  110  112  113  117  121  126  127  128  133  137  140  146  157\n",
      "  159  160  161  162  163  164  165  166  170  173  180  185  188  190\n",
      "  192  199  202  204  205  208  217  218  219  225  227  230  235  236\n",
      "  237  241  243  247  255  256  258  262  264  267  269  272  274  275\n",
      "  277  279  284  285  286  288  289  292  293  294  296  301  307  308\n",
      "  310  313  321  323  324  325  326  327  333  334  335  340  342  347\n",
      "  351  354  360  362  363  365  366  373  375  379  381  385  388  399\n",
      "  405  407  411  412  416  419  423  424  425  428  434  435  437  440\n",
      "  441  452  455  458  463  465  475  479  490  496  497  500  502  504\n",
      "  505  509  516  522  523  524  529  530  531  535  537  539  541  542\n",
      "  544  548  552  555  558  560  563  566  567  573  574  575  576  577\n",
      "  579  581  589  591  592  597  600  601  605  608  616  618  621  623\n",
      "  630  631  633  644  655  656  658  661  664  674  680  694  697  699\n",
      "  700  704  707  708  709  712  714  718  719  720  721  723  727  728\n",
      "  738  746  749  756  757  761  763  766  767  771  773  775  777  786\n",
      "  787  792  794  795  800  803  806  808  809  814  815  817  821  825\n",
      "  828  835  837  841  842  843  848  850  853  855  857  858  860  861\n",
      "  862  863  866  869  870  874  875  881  882  886  890  892  893  898\n",
      "  899  900  904  905  906  907  909  912  916  917  919  926  927  930\n",
      "  932  937  939  940  941  942  943  944  945  949  950  956  960  962\n",
      "  965  971  972  975  976  983  985  990  991  992  994  995  996 1001\n",
      " 1002 1005 1012 1013 1014 1016 1023 1030 1036 1037 1041 1042 1043 1055\n",
      " 1056 1058 1060 1064 1066 1070 1076 1082 1093 1094 1096 1103 1107 1108\n",
      " 1109 1111 1112 1113 1116 1117 1121 1124 1125 1126 1130 1134 1135 1136\n",
      " 1137 1144 1150 1151 1152 1155 1156 1160 1161 1162 1164 1166 1181 1183\n",
      " 1186 1188 1189 1194 1195 1202 1207 1208 1209 1210 1211 1213 1214 1220\n",
      " 1224 1225 1226 1227 1230 1231 1235 1236 1247 1249 1251 1252 1253]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'(array([   0,    1,    2,    4,    6,    7,    9,   10,   11,   13,   14,\n         16,   21,   22,   23,   24,   28,   30,   31,   33,   34,   35,\n         36,   37,   38,   42,   44,   47,   48,   49,   50,   51,   53,\n         55,   59,   60,   63,   64,   66,   67,   71,   72,   73,   75,\n         78,   79,   80,   81,   82,   83,   84,   86,   90,   92,   94,\n         95,   96,   98,   99,  101,  102,  103,  104,  105,  106,  107,\n        108,  111,  114,  115,  116,  118,  119,  120,  122,  123,  124,\n        125,  129,  130,  131,  132,  134,  135,  136,  138,  139,  141,\n        142,  143,  144,  145,  147,  148,  149,  150,  151,  152,  153,\n        154,  155,  156,  158,  167,  168,  169,  171,  172,  174,  175,\n        176,  177,  178,  179,  181,  182,  183,  184,  186,  187,  189,\n        191,  193,  194,  195,  196,  197,  198,  200,  201,  203,  206,\n        207,  209,  210,  211,  212,  213,  214,  215,  216,  220,  221,\n        222,  223,  224,  226,  228,  229,  231,  232,  233,  234,  238,\n        239,  240,  242,  244,  245,  246,  248,  249,  250,  251,  252,\n        253,  254,  257,  259,  260,  261,  263,  265,  266,  268,  270,\n        271,  273,  276,  278,  280,  281,  282,  283,  287,  290,  291,\n        295,  297,  298,  299,  300,  302,  303,  304,  305,  306,  309,\n        311,  312,  314,  315,  316,  317,  318,  319,  320,  322,  328,\n        329,  330,  331,  332,  336,  337,  338,  339,  341,  343,  344,\n        345,  346,  348,  349,  350,  352,  353,  355,  356,  357,  358,\n        359,  361,  364,  367,  368,  369,  370,  371,  372,  374,  376,\n        377,  378,  380,  382,  383,  384,  386,  387,  389,  390,  391,\n        392,  393,  394,  395,  396,  397,  398,  400,  401,  402,  403,\n        404,  406,  408,  409,  410,  413,  414,  415,  417,  418,  420,\n        421,  422,  426,  427,  429,  430,  431,  432,  433,  436,  438,\n        439,  442,  443,  444,  445,  446,  447,  448,  449,  450,  451,\n        453,  454,  456,  457,  459,  460,  461,  462,  464,  466,  467,\n        468,  469,  470,  471,  472,  473,  474,  476,  477,  478,  480,\n        481,  482,  483,  484,  485,  486,  487,  488,  489,  491,  492,\n        493,  494,  495,  498,  499,  501,  503,  506,  507,  508,  510,\n        511,  512,  513,  514,  515,  517,  518,  519,  520,  521,  525,\n        526,  527,  528,  532,  533,  534,  536,  538,  540,  543,  545,\n        546,  547,  549,  550,  551,  553,  554,  556,  557,  559,  561,\n        562,  564,  565,  568,  569,  570,  571,  572,  578,  580,  582,\n        583,  584,  585,  586,  587,  588,  590,  593,  594,  595,  596,\n        598,  599,  602,  603,  604,  606,  607,  609,  610,  611,  612,\n        613,  614,  615,  617,  619,  620,  622,  624,  625,  626,  627,\n        628,  629,  632,  634,  635,  636,  637,  638,  639,  640,  641,\n        642,  643,  645,  646,  647,  648,  649,  650,  651,  652,  653,\n        654,  657,  659,  660,  662,  663,  665,  666,  667,  668,  669,\n        670,  671,  672,  673,  675,  676,  677,  678,  679,  681,  682,\n        683,  684,  685,  686,  687,  688,  689,  690,  691,  692,  693,\n        695,  696,  698,  701,  702,  703,  705,  706,  710,  711,  713,\n        715,  716,  717,  722,  724,  725,  726,  729,  730,  731,  732,\n        733,  734,  735,  736,  737,  739,  740,  741,  742,  743,  744,\n        745,  747,  748,  750,  751,  752,  753,  754,  755,  758,  759,\n        760,  762,  764,  765,  768,  769,  770,  772,  774,  776,  778,\n        779,  780,  781,  782,  783,  784,  785,  788,  789,  790,  791,\n        793,  796,  797,  798,  799,  801,  802,  804,  805,  807,  810,\n        811,  812,  813,  816,  818,  819,  820,  822,  823,  824,  826,\n        827,  829,  830,  831,  832,  833,  834,  836,  838,  839,  840,\n        844,  845,  846,  847,  849,  851,  852,  854,  856,  859,  864,\n        865,  867,  868,  871,  872,  873,  876,  877,  878,  879,  880,\n        883,  884,  885,  887,  888,  889,  891,  894,  895,  896,  897,\n        901,  902,  903,  908,  910,  911,  913,  914,  915,  918,  920,\n        921,  922,  923,  924,  925,  928,  929,  931,  933,  934,  935,\n        936,  938,  946,  947,  948,  951,  952,  953,  954,  955,  957,\n        958,  959,  961,  963,  964,  966,  967,  968,  969,  970,  973,\n        974,  977,  978,  979,  980,  981,  982,  984,  986,  987,  988,\n        989,  993,  997,  998,  999, 1000, 1003, 1004, 1006, 1007, 1008,\n       1009, 1010, 1011, 1015, 1017, 1018, 1019, 1020, 1021, 1022, 1024,\n       1025, 1026, 1027, 1028, 1029, 1031, 1032, 1033, 1034, 1035, 1038,\n       1039, 1040, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052,\n       1053, 1054, 1057, 1059, 1061, 1062, 1063, 1065, 1067, 1068, 1069,\n       1071, 1072, 1073, 1074, 1075, 1077, 1078, 1079, 1080, 1081, 1083,\n       1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1095, 1097,\n       1098, 1099, 1100, 1101, 1102, 1104, 1105, 1106, 1110, 1114, 1115,\n       1118, 1119, 1120, 1122, 1123, 1127, 1128, 1129, 1131, 1132, 1133,\n       1138, 1139, 1140, 1141, 1142, 1143, 1145, 1146, 1147, 1148, 1149,\n       1153, 1154, 1157, 1158, 1159, 1163, 1165, 1167, 1168, 1169, 1170,\n       1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1182,\n       1184, 1185, 1187, 1190, 1191, 1192, 1193, 1196, 1197, 1198, 1199,\n       1200, 1201, 1203, 1204, 1205, 1206, 1212, 1215, 1216, 1217, 1218,\n       1219, 1221, 1222, 1223, 1228, 1229, 1232, 1233, 1234, 1237, 1238,\n       1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1248, 1250, 1254,\n       1255]), slice(None, None, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-245e3b68df4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(array([   0,    1,    2,    4,    6,    7,    9,   10,   11,   13,   14,\n         16,   21,   22,   23,   24,   28,   30,   31,   33,   34,   35,\n         36,   37,   38,   42,   44,   47,   48,   49,   50,   51,   53,\n         55,   59,   60,   63,   64,   66,   67,   71,   72,   73,   75,\n         78,   79,   80,   81,   82,   83,   84,   86,   90,   92,   94,\n         95,   96,   98,   99,  101,  102,  103,  104,  105,  106,  107,\n        108,  111,  114,  115,  116,  118,  119,  120,  122,  123,  124,\n        125,  129,  130,  131,  132,  134,  135,  136,  138,  139,  141,\n        142,  143,  144,  145,  147,  148,  149,  150,  151,  152,  153,\n        154,  155,  156,  158,  167,  168,  169,  171,  172,  174,  175,\n        176,  177,  178,  179,  181,  182,  183,  184,  186,  187,  189,\n        191,  193,  194,  195,  196,  197,  198,  200,  201,  203,  206,\n        207,  209,  210,  211,  212,  213,  214,  215,  216,  220,  221,\n        222,  223,  224,  226,  228,  229,  231,  232,  233,  234,  238,\n        239,  240,  242,  244,  245,  246,  248,  249,  250,  251,  252,\n        253,  254,  257,  259,  260,  261,  263,  265,  266,  268,  270,\n        271,  273,  276,  278,  280,  281,  282,  283,  287,  290,  291,\n        295,  297,  298,  299,  300,  302,  303,  304,  305,  306,  309,\n        311,  312,  314,  315,  316,  317,  318,  319,  320,  322,  328,\n        329,  330,  331,  332,  336,  337,  338,  339,  341,  343,  344,\n        345,  346,  348,  349,  350,  352,  353,  355,  356,  357,  358,\n        359,  361,  364,  367,  368,  369,  370,  371,  372,  374,  376,\n        377,  378,  380,  382,  383,  384,  386,  387,  389,  390,  391,\n        392,  393,  394,  395,  396,  397,  398,  400,  401,  402,  403,\n        404,  406,  408,  409,  410,  413,  414,  415,  417,  418,  420,\n        421,  422,  426,  427,  429,  430,  431,  432,  433,  436,  438,\n        439,  442,  443,  444,  445,  446,  447,  448,  449,  450,  451,\n        453,  454,  456,  457,  459,  460,  461,  462,  464,  466,  467,\n        468,  469,  470,  471,  472,  473,  474,  476,  477,  478,  480,\n        481,  482,  483,  484,  485,  486,  487,  488,  489,  491,  492,\n        493,  494,  495,  498,  499,  501,  503,  506,  507,  508,  510,\n        511,  512,  513,  514,  515,  517,  518,  519,  520,  521,  525,\n        526,  527,  528,  532,  533,  534,  536,  538,  540,  543,  545,\n        546,  547,  549,  550,  551,  553,  554,  556,  557,  559,  561,\n        562,  564,  565,  568,  569,  570,  571,  572,  578,  580,  582,\n        583,  584,  585,  586,  587,  588,  590,  593,  594,  595,  596,\n        598,  599,  602,  603,  604,  606,  607,  609,  610,  611,  612,\n        613,  614,  615,  617,  619,  620,  622,  624,  625,  626,  627,\n        628,  629,  632,  634,  635,  636,  637,  638,  639,  640,  641,\n        642,  643,  645,  646,  647,  648,  649,  650,  651,  652,  653,\n        654,  657,  659,  660,  662,  663,  665,  666,  667,  668,  669,\n        670,  671,  672,  673,  675,  676,  677,  678,  679,  681,  682,\n        683,  684,  685,  686,  687,  688,  689,  690,  691,  692,  693,\n        695,  696,  698,  701,  702,  703,  705,  706,  710,  711,  713,\n        715,  716,  717,  722,  724,  725,  726,  729,  730,  731,  732,\n        733,  734,  735,  736,  737,  739,  740,  741,  742,  743,  744,\n        745,  747,  748,  750,  751,  752,  753,  754,  755,  758,  759,\n        760,  762,  764,  765,  768,  769,  770,  772,  774,  776,  778,\n        779,  780,  781,  782,  783,  784,  785,  788,  789,  790,  791,\n        793,  796,  797,  798,  799,  801,  802,  804,  805,  807,  810,\n        811,  812,  813,  816,  818,  819,  820,  822,  823,  824,  826,\n        827,  829,  830,  831,  832,  833,  834,  836,  838,  839,  840,\n        844,  845,  846,  847,  849,  851,  852,  854,  856,  859,  864,\n        865,  867,  868,  871,  872,  873,  876,  877,  878,  879,  880,\n        883,  884,  885,  887,  888,  889,  891,  894,  895,  896,  897,\n        901,  902,  903,  908,  910,  911,  913,  914,  915,  918,  920,\n        921,  922,  923,  924,  925,  928,  929,  931,  933,  934,  935,\n        936,  938,  946,  947,  948,  951,  952,  953,  954,  955,  957,\n        958,  959,  961,  963,  964,  966,  967,  968,  969,  970,  973,\n        974,  977,  978,  979,  980,  981,  982,  984,  986,  987,  988,\n        989,  993,  997,  998,  999, 1000, 1003, 1004, 1006, 1007, 1008,\n       1009, 1010, 1011, 1015, 1017, 1018, 1019, 1020, 1021, 1022, 1024,\n       1025, 1026, 1027, 1028, 1029, 1031, 1032, 1033, 1034, 1035, 1038,\n       1039, 1040, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052,\n       1053, 1054, 1057, 1059, 1061, 1062, 1063, 1065, 1067, 1068, 1069,\n       1071, 1072, 1073, 1074, 1075, 1077, 1078, 1079, 1080, 1081, 1083,\n       1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1095, 1097,\n       1098, 1099, 1100, 1101, 1102, 1104, 1105, 1106, 1110, 1114, 1115,\n       1118, 1119, 1120, 1122, 1123, 1127, 1128, 1129, 1131, 1132, 1133,\n       1138, 1139, 1140, 1141, 1142, 1143, 1145, 1146, 1147, 1148, 1149,\n       1153, 1154, 1157, 1158, 1159, 1163, 1165, 1167, 1168, 1169, 1170,\n       1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1182,\n       1184, 1185, 1187, 1190, 1191, 1192, 1193, 1196, 1197, 1198, 1199,\n       1200, 1201, 1203, 1204, 1205, 1206, 1212, 1215, 1216, 1217, 1218,\n       1219, 1221, 1222, 1223, 1228, 1229, 1232, 1233, 1234, 1237, 1238,\n       1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1248, 1250, 1254,\n       1255]), slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "normalization=\"Standard\"\n",
    "num_test=3\n",
    "seeds = np.random.randint(1000, size=num_runs)\n",
    "run = 0\n",
    "\n",
    "category= \"Origin\"\n",
    "X = df.copy()\n",
    "y = X.pop(category).values\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"Starting CV\")\n",
    "    #Provides train/test indices to split data in train/test sets.\n",
    "    skf = StratifiedKFold(n_splits=num_test, shuffle=True, random_state=seed)\n",
    "    fold = 0\n",
    "    \n",
    "    # Hypertunning before K folds - Random Forest\n",
    "    try: # If it was run before, don't run again\n",
    "        best_rf_parameters\n",
    "    except:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)\n",
    "        best_rf_parameters = parameter_tunning_RF()\n",
    "    print(\"RandomSearchCV best parameters for Random Forest: \" + str(best_rf_parameters))\n",
    "    \n",
    "    # Stratified k-fold\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        # Select and format training and testing sets\n",
    "        print(train_index)\n",
    "        print(test_index)\n",
    "        X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        cl =  np.unique(y_train)\n",
    "        num_class = len(cl)\n",
    "        \n",
    "        ###################################################################################\n",
    "        # RANDOM FOREST\n",
    "        if train_rf == \"True\":\n",
    "        # Already use best parameters from Hyperparameter tunning\n",
    "            rfc = RandomForestClassifier(n_estimators=best_rf_parameters[\"n_estimators\"], \n",
    "                                         max_features=best_rf_parameters[\"max_features\"], \n",
    "                                         max_depth=best_rf_parameters[\"max_depth\"])\n",
    "\n",
    "            # Fit model\n",
    "            rfc.fit(X_train,y_train)\n",
    "        \n",
    "            # Get predicted labels for the test data:\n",
    "            rfc_predict = rfc.predict(X_test)\n",
    "\n",
    "            # Get ranking of feature importance\n",
    "            feature_importance = rfc.feature_importances_\n",
    "        \n",
    "            stat_dict = get_stats(y_test, rfc_predict, rfc)\n",
    "            \n",
    "            rf_scores[\"Run_\" + str(run) + \"_CV_\" + str(fold)] = feature_importance\n",
    "        \n",
    "            auc_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"AUC\"]\n",
    "            mcc_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"MCC\"]\n",
    "            precision_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"Precision\"]\n",
    "            recall_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"Recall\"]\n",
    "            f1_df.loc[\"RF\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict[\"F1\"]\n",
    "\n",
    "            sys.stdout.write(\"\")\n",
    "            print(\"# RF:\\t\\t\\t%f\\t%f\" % (stat_dict[\"AUC\"], auc_df.loc[\"RF\"].mean(axis=0)))    \n",
    "    \n",
    "        fold +=1\n",
    "    run +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df.to_csv(\"Evaluation_dfs/auc_df.csv\")\n",
    "mcc_df.to_csv(\"Evaluation_dfs/mcc_df.csv\")\n",
    "precision_df.to_csv(\"Evaluation_dfs/precision_df.csv\")\n",
    "recall_df.to_csv(\"Evaluation_dfs/recall_df.csv\")\n",
    "f1_df.to_csv(\"Evaluation_dfs/f1_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                          X. Choosing best model                             #\n",
    "###############################################################################\n",
    "\n",
    "results_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=to_train)\n",
    "results_df_nr = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=to_train)\n",
    "\n",
    "for model in to_train:\n",
    "    results_df.loc[\"AUC\"][model] = \"{:.2f}\".format(auc_df.loc[model].mean())+ \" (\" + \"{:.2f}\".format(auc_df.loc[model].std()) + \")\"     \n",
    "    results_df_nr.loc[\"AUC\"][model] = auc_df.loc[model].mean()   \n",
    "    \n",
    "    results_df.loc[\"MCC\"][model] = \"{:.2f}\".format(mcc_df.loc[model].mean()) + \" (\" + \"{:.2f}\".format(mcc_df.loc[model].std()) + \")\"\n",
    "    results_df_nr.loc[\"MCC\"][model] = mcc_df.loc[model].mean()   \n",
    "    \n",
    "    results_df.loc[\"Precision\"][model] = \"{:.2f}\".format(precision_df.loc[model].mean()) + \" (\" + \"{:.2f}\".format(precision_df.loc[model].std()) + \")\"\n",
    "    results_df_nr.loc[\"Precision\"][model] = precision_df.loc[model].mean()   \n",
    "\n",
    "    results_df.loc[\"Recall\"][model] = \"{:.2f}\".format(recall_df.loc[model].mean()) + \" (\" + \"{:.2f}\".format(recall_df.loc[model].std()) + \")\"\n",
    "    results_df_nr.loc[\"Recall\"][model] = recall_df.loc[model].mean()   \n",
    "\n",
    "    results_df.loc[\"F1\"][model] = \"{:.2f}\".format(f1_df.loc[model].mean()) + \" (\" + \"{:.2f}\".format(f1_df.loc[model].std()) + \")\"\n",
    "    results_df_nr.loc[\"F1\"][model] = f1_df.loc[model].mean()   \n",
    "\n",
    "# Find model with best metrics    \n",
    "results_df_nr.loc[\"Total\",:] = results_df_nr.sum(axis=0).divide(5).round(2)\n",
    "\n",
    "best={}\n",
    "for model in to_train:\n",
    "    best[model] = results_df_nr.loc[\"Total\",:][model]\n",
    "    \n",
    "best_model = max(best, key=best.get)\n",
    "\n",
    "print(\"Results - mean & standard deviation values per model: \")\n",
    "print(results_df.head(20))\n",
    "print(\"\")\n",
    "print(\"Best model: \" + str(best_model))\n",
    "\n",
    "results_df.to_csv(\"Evaluation_dfs/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "\n",
    "rf_ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "svm_ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "\n",
    "model_rankings = {}\n",
    "\n",
    "if \"RF\" in to_train:\n",
    "    for col in rf_scores.columns:\n",
    "        rank_list = rf_scores[col].rank(ascending=False).sort_values(ascending=True).index.values\n",
    "        ranking_df[\"RF_\" + col] = rank_list\n",
    "        rf_ranking_df[\"RF_\" + col] = rank_list\n",
    "\n",
    "        model_rankings[\"RF\"] = rf_scores.median(axis=1).sort_values(ascending=False).index.values\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores.median(axis=1).sort_values(ascending=True).plot(kind=\"barh\", figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"RF\" in to_train:\n",
    "    rf_ranking_df.to_csv(\"Evaluation_dfs/rf_feature_ranks.csv\")\n",
    "    rf_scores.to_csv(\"Evaluation_dfs/rf_feature_scores.csv\")\n",
    "    np.savetxt(\"Evaluation_dfs/rf_rank_list.txt\", model_rankings[\"RF\"], fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection implementation\n",
    "if best_model == \"RF\":\n",
    "    rfc = RandomForestClassifier(n_estimators=best_rf_parameters[\"n_estimators\"], \n",
    "                                         max_features=best_rf_parameters[\"max_features\"], \n",
    "                                         max_depth=best_rf_parameters[\"max_depth\"])\n",
    "    # Fit model\n",
    "    rfc.fit(X_train,y_train)    \n",
    "    \n",
    "    # Get predicted labels for the test data:\n",
    "    rfc_predict = rfc.predict(X_test)\n",
    "\n",
    "    # Cross-validation\n",
    "    scores = cross_val_score(rfc, X, y, cv=5)\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "    \n",
    "    # Get ranking of feature importance\n",
    "    feature_importance = rfc.feature_importances_\n",
    "        \n",
    "    stat_dict_final = get_stats(y_test, rfc_predict, rfc)\n",
    "\n",
    "        \n",
    "rf_scores[\"Run_\" + str(run) + \"_CV_\" + str(fold)] = feature_importance\n",
    "        \n",
    "auc_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"AUC\"]\n",
    "mcc_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"MCC\"]\n",
    "precision_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"Precision\"]\n",
    "recall_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"Recall\"]\n",
    "f1_df.loc[best_model][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stat_dict_final[\"F1\"]\n",
    "\n",
    "sys.stdout.write(\"\")\n",
    "print(str(best_model) + \" AUC: \" + str(stat_dict_final[\"AUC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "rf = RandomForestClassifier(n_estimators = 100, class_weight='balanced', random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"lightsalmon\", align=\"center\")\n",
    "#plt.xticks(range(X_train.shape[1]), X_train.feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category= \"Origin\"\n",
    "X = df.copy()\n",
    "y = X.pop(category).values\n",
    "\n",
    "###############################################################################\n",
    "#                        3. Create train and test set                         #\n",
    "###############################################################################\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,\n",
    "                                                    random_state = 1000)\n",
    "print(X_train.shape)\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "result = permutation_importance(rfc, X_test, y_test, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_test.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "\n",
    "rfecv = RFECV(estimator=rfc, \n",
    "              step=1, \n",
    "              cv=StratifiedKFold(2),\n",
    "              scoring='accuracy',\n",
    "              n_jobs=-1,\n",
    "              min_features_to_select=min_features_to_select)\n",
    "\n",
    "rfecv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected features labels\n",
    "feature_names = df.columns\n",
    "selected_features = feature_names[feature_selector.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "\n",
    "rf_ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "svm_ranking_df = pd.DataFrame(index=range(len(features)))\n",
    "\n",
    "model_rankings = {}\n",
    "        \n",
    "if \"RF\" in to_train:\n",
    "    for col in rf_scores.columns:\n",
    "        rank_list = rf_scores[col].rank(ascending=False).sort_values(ascending=True).index.values\n",
    "        ranking_df[\"RF_\" + col] = rank_list\n",
    "        rf_ranking_df[\"RF_\" + col] = rank_list\n",
    "    model_rankings[\"RF\"] = rf_scores.median(axis=1).sort_values(ascending=False).index.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    if \"RF\" in to_train:\n",
    "        rf_median_scores = rf_scores.median(axis=1)        \n",
    "        fig = plt.figure(dpi=300, figsize=(9,9), tight_layout=True)\n",
    "        \n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.title(\"RF Feature Scores\")\n",
    "        sns.distplot(list(rf_median_scores))\n",
    "        plt.savefig(\"RF_scores.png\")\n",
    "        #plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def generate_score_distributions():\n",
    "\n",
    "    if \"RF\" in to_train:\n",
    "        rf_median_scores = rf_scores.median(axis=1)        \n",
    "        fig = plt.figure(dpi=300, figsize=(9,9), tight_layout=True)\n",
    "        \n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.title(\"RF Feature Scores\")\n",
    "        sns.distplot(list(rf_median_scores))\n",
    "        plt.savefig(\"RF_scores.png\")\n",
    "        #plt.clf()\n",
    "\n",
    "    if \"SVM\" in to_train:\n",
    "        fig = plt.figure(dpi=300, figsize=(9,9), tight_layout=True)\n",
    "\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.title(\"SVM Feature Scores\")\n",
    "        if num_class == 2:\n",
    "            svm_median_scores = svm_scores.median(axis=1).values\n",
    "            sns.distplot(svm_median_scores)\n",
    "        else:\n",
    "            for l in label_set:\n",
    "                svm_median_scores = svm_scores[l].median(axis=1).values  \n",
    "                sns.distplot(svm_median_scores, label=str(l).title())\n",
    "            plt.legend()\n",
    "        plt.savefig(\"SVM_scores.png\")\n",
    "        #plt.clf()\n",
    "\n",
    "    return\n",
    "\n",
    "generate_score_distributions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
